{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbx50ZZN6mr5Hdbq4vGjcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffeldhaus/conversational-agents-intent-improver-agent/blob/main/Improve_Conversational_Agents_(Dialogflow_CX)_Intents_via_Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPO7-dyafunE"
      },
      "outputs": [],
      "source": [
        "#@title Install required packages\n",
        "\n",
        "!pip install --quiet google-cloud-dialogflow-cx google-genai tqdm langcodes XlsxWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import required packages\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import io\n",
        "import re\n",
        "import uuid\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "from google.api_core import retry\n",
        "from google.api_core.client_options import ClientOptions\n",
        "\n",
        "from google.cloud import dialogflowcx_v3 as dialogflow\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from langcodes import Language"
      ],
      "metadata": {
        "id": "XJPlj7kWm9n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration { display-mode: \"form\" }\n",
        "\n",
        "# @markdown # Dialogflow CX Agent Configuration\n",
        "# @markdown The full name of the Dialogflow CX agent, including the project and location:\n",
        "AGENT_NAME = \"projects/ucds-testsystem/locations/europe-west3/agents/e444b62c-6b83-489b-b41c-373c62093972\" # @param {type:\"string\"}\n",
        "# @markdown The ID of the flow to be tested within the agent:\n",
        "FLOW_ID = \"135bf7a3-7481-4e69-923b-f9dcfc4bec6e\" # @param {type:\"string\"}\n",
        "# @markdown The ID of the page where the test will start:\n",
        "PAGE_ID = \"b9d110b1-d061-471a-a568-68f6198efcb3\" # @param {type:\"string\"}\n",
        "# @markdown  The language code to use for the test (e.g., \"en\", \"de\"). If left empty, the agent's default language will be used:\n",
        "LANGUAGE_CODE = \"\" # @param {type:\"string\"}\n",
        "# @markdown The NLU classification threshold for including alternative intents in the match results:\n",
        "NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS = 0.0001 # @param {type:\"number\"}\n",
        "# @markdown The proportion of the test data to be used for the final evaluation (the rest will be used for reinforcement learning):\n",
        "TEST_TRAIN_SPLIT_RATE = 0.6 # @param {type:\"number\"}\n",
        "# @markdown The number of reinforcement learning iterations to perform:\n",
        "REINFORCEMENT_ITERATIONS = 2 # @param {type:\"number\"}\n",
        "# @markdown The minimum confidence difference between the top matched intent and the second-best alternative to be considered a \"good\" match:\n",
        "REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE = 0.2 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown # Gemini API Configuration\n",
        "# @markdown The name of the Gemini model to use for analysis:\n",
        "GEMINI_MODEL = \"gemini-2.5-pro\" # @param {type:\"string\"}\n",
        "# @markdown The Google Cloud project ID where the Gemini API is enabled:\n",
        "GEMINI_PROJECT_ID = \"emea-ccai-demo\" # @param {type:\"string\"}\n",
        "# @markdown The Google Cloud location where the Gemini API is located:\n",
        "GEMINI_LOCATION = \"europe-west4\" # @param {type:\"string\"}\n",
        "# @markdown The maximum number of tokens to use in a single call to the Gemini API:\n",
        "MAX_TOKEN_COUNT = 1048575 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown # General Configuration\n",
        "# @markdown The maximum number of parallel threads to use for tasks like evaluation and Gemini analysis:\n",
        "MAX_WORKERS = 8 # @param {type:\"integer\"}\n",
        "\n",
        "# Extract the project ID from the agent name\n",
        "PROJECT_ID = AGENT_NAME.split('/')[1]\n",
        "# Extract the location from the agent name\n",
        "LOCATION = AGENT_NAME.split('/')[3]"
      ],
      "metadata": {
        "id": "SdrdoeMFgcg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Authenticate\n",
        "\n",
        "auth.authenticate_user(project_id=PROJECT_ID)"
      ],
      "metadata": {
        "id": "0hOpiC_rn4nz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize\n",
        "\n",
        "# Initialize genai Client for Gemini usage\n",
        "genai_client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=GEMINI_PROJECT_ID,\n",
        "    location=GEMINI_LOCATION,\n",
        "    http_options=types.HttpOptions(\n",
        "        retry_options=types.HttpRetryOptions(\n",
        "            attempts=3,\n",
        "            initial_delay=3,\n",
        "            exp_base=2,\n",
        "            max_delay=60,\n",
        "            http_status_codes=[429, 500, 502, 503, 504]\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# Initialize Dialogflow CX Clients with the correct endpoint\n",
        "\n",
        "if LOCATION != \"global\":\n",
        "  api_endpoint=f\"{LOCATION}-dialogflow.googleapis.com\"\n",
        "else:\n",
        "  api_endpoint=f\"dialogflow.googleapis.com\"\n",
        "\n",
        "client_options = ClientOptions(api_endpoint=api_endpoint)\n",
        "agents_client = dialogflow.AgentsClient(client_options=client_options)\n",
        "flows_client = dialogflow.FlowsClient(client_options=client_options)\n",
        "pages_client = dialogflow.PagesClient(client_options=client_options)\n",
        "intents_client = dialogflow.IntentsClient(client_options=client_options)\n",
        "entity_types_client = dialogflow.EntityTypesClient(client_options=client_options)\n",
        "sessions_client = dialogflow.SessionsClient(client_options=client_options)"
      ],
      "metadata": {
        "id": "z49rhwmk-k8h",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Get Dialogflow CX resources\n",
        "\n",
        "# Read the agent\n",
        "agent = agents_client.get_agent(name=AGENT_NAME)\n",
        "print(f\"Agent read successfully: {agent.display_name}\")\n",
        "\n",
        "# fallback to default language code\n",
        "if not LANGUAGE_CODE:\n",
        "  LANGUAGE_CODE = agent.default_language_code\n",
        "\n",
        "# get language name\n",
        "language = Language.get(LANGUAGE_CODE).language_name(\"en\")\n",
        "print(f\"Using Language: {language} ({LANGUAGE_CODE})\")\n",
        "\n",
        "# Get Flow\n",
        "flow = flows_client.get_flow(name=f\"{AGENT_NAME}/flows/{FLOW_ID}\")\n",
        "print(f\"Flow read successfully: {flow.display_name}\")\n",
        "\n",
        "# Get Page\n",
        "page = pages_client.get_page(name=f\"{AGENT_NAME}/flows/{FLOW_ID}/pages/{PAGE_ID}\")\n",
        "print(f\"Page read successfully: {page.display_name}\")\n",
        "\n",
        "# Get Intents\n",
        "intents = list(intents_client.list_intents(parent=AGENT_NAME))\n",
        "print(f\"Intents read successfully: {len(intents)}\")\n",
        "\n",
        "# Get Entity Types\n",
        "entity_types = list(entity_types_client.list_entity_types(parent=AGENT_NAME))\n",
        "print(f\"Entity types read successfully: {len(entity_types)}\")"
      ],
      "metadata": {
        "id": "ctbAQ-G5mNyO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check and update NLU threshold and training mode for the flow\n",
        "\n",
        "if NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS != 0 and flow.nlu_settings.classification_threshold != NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS:\n",
        "    flow.nlu_settings.classification_threshold = NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS\n",
        "    flows_client.update_flow(request={\"flow\": flow})\n",
        "    print(f\"NLU threshold updated for flow {flow.display_name} to {NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS}\")\n",
        "else:\n",
        "    print(f\"NLU threshold for flow {flow.display_name} is already {flow.nlu_settings.classification_threshold} or NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS is 0. No update needed.\")\n",
        "\n",
        "if flow.nlu_settings.model_training_mode != dialogflow.types.NluSettings.ModelTrainingMode.MODEL_TRAINING_MODE_MANUAL:\n",
        "    flow.nlu_settings.model_training_mode = dialogflow.types.NluSettings.ModelTrainingMode.MODEL_TRAINING_MODE_MANUAL\n",
        "    flows_client.update_flow(request={\"flow\": flow})\n",
        "    print(f\"Training mode updated for flow {flow.display_name} to MANUAL\")\n",
        "else:\n",
        "    print(f\"Training mode for flow {flow.display_name} is already MANUAL. No update needed.\")"
      ],
      "metadata": {
        "id": "goV6Yy2RsEor",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload XLSX or CSV file(s) with test sentences and matching intents\n",
        "\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "all_sentences = {}\n",
        "\n",
        "# Create a dictionary to map intent display names to UUIDs\n",
        "intent_display_name_to_uuid = {intent.display_name: intent.name.split('/')[-1] for intent in intents}\n",
        "\n",
        "for file_name, file_content in uploaded_files.items():\n",
        "    print(f\"Processing file: {file_name}\")\n",
        "    try:\n",
        "        if file_name.endswith('.csv'):\n",
        "            df = pd.read_csv(io.BytesIO(file_content), on_bad_lines='warn')\n",
        "        elif file_name.endswith('.xlsx'):\n",
        "            df = pd.read_excel(io.BytesIO(file_content))\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file type: {file_name}\")\n",
        "            continue\n",
        "\n",
        "        # Assume the first row is header and the data starts from the second row\n",
        "        # Rename columns for easier access\n",
        "        df.columns = ['Intent', 'Test']\n",
        "\n",
        "\n",
        "        # Process data: Assume column 1 is intent, column 2 is test sentence\n",
        "        for index, row in df.iterrows():\n",
        "            intent_from_file = str(row['Intent']).strip()\n",
        "            sentence = str(row['Test']).strip()\n",
        "\n",
        "            if not sentence: # Skip if sentence is empty\n",
        "                continue\n",
        "\n",
        "            # Check if intent is a UUID\n",
        "            if re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', intent_from_file):\n",
        "                intent_uuid = intent_from_file\n",
        "            # Check if intent is a display name and exists in the agent's intents\n",
        "            elif intent_from_file in intent_display_name_to_uuid:\n",
        "                intent_uuid = intent_display_name_to_uuid[intent_from_file]\n",
        "            else:\n",
        "                print(f\"Ignoring row {index} in {file_name}: Invalid intent '{intent_from_file}'. Not a valid UUID or a known display name.\")\n",
        "                continue\n",
        "\n",
        "            if intent_uuid not in all_sentences:\n",
        "                all_sentences[intent_uuid] = []\n",
        "            all_sentences[intent_uuid].append(sentence)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "print(f\"\\nProcessed {len(all_sentences)} intents with a total of {sum(len(sentences) for sentences in all_sentences.values())} test sentences.\")"
      ],
      "metadata": {
        "id": "5VU24vHJg3ji",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d622e437",
        "cellView": "form"
      },
      "source": [
        "#@title Split test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "# Initialize empty dictionaries for training and testing sets\n",
        "train_sentences = {}\n",
        "test_sentences = {}\n",
        "\n",
        "# Total counts for final printout\n",
        "total_train_count = 0\n",
        "total_test_count = 0\n",
        "\n",
        "for intent_uuid, sentences in all_sentences.items():\n",
        "    if len(sentences) < 2:\n",
        "      print(f\"Not enough sentences for intent {intent_uuid} to have at least 1 train and 1 test sentence\")\n",
        "      continue\n",
        "\n",
        "    # manual split for small number of sentences to ensure at least 1 test and 1 train sentence\n",
        "    if len(sentences) <= 3:\n",
        "        test_list = sentences[:1]\n",
        "        train_list = sentences[1:]\n",
        "    else:\n",
        "        # Split the sentences for the current intent\n",
        "        train_list, test_list = train_test_split(sentences, test_size=TEST_TRAIN_SPLIT_RATE, random_state=42)\n",
        "\n",
        "    # Add the results to the dictionaries\n",
        "    if train_list:\n",
        "        if intent_uuid not in train_sentences:\n",
        "            train_sentences[intent_uuid] = []\n",
        "        train_sentences[intent_uuid].extend(train_list)\n",
        "        total_train_count += len(train_list)\n",
        "\n",
        "    if test_list:\n",
        "        if intent_uuid not in test_sentences:\n",
        "            test_sentences[intent_uuid] = []\n",
        "        test_sentences[intent_uuid].extend(test_list)\n",
        "        total_test_count += len(test_list)\n",
        "\n",
        "print(f\"Total sentences: {total_train_count + total_test_count}\")\n",
        "print(f\"Training sentences: {total_train_count}\")\n",
        "print(f\"Testing sentences for evaluation: {total_test_count}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d676bcd"
      },
      "source": [
        "## Reinforcement Learning Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37f7f281",
        "cellView": "form"
      },
      "source": [
        "#@title Analyze Intent with Gemini functions\n",
        "\n",
        "@retry.Retry(\n",
        "    initial=60,\n",
        "    maximum=300,\n",
        "    timeout=600,\n",
        ")\n",
        "def match_intent(agent_name, text, session_id, flow_id, page_id, language_code, timeout=10):\n",
        "    \"\"\"Returns the result of detect intent with texts as inputs.\n",
        "\n",
        "    Using the same `session_id` between requests allows continuation of the conversation.\"\"\"\n",
        "    session_path = f\"{agent_name}/sessions/{session_id}\"\n",
        "    current_page_path = f\"{agent_name}/flows/{flow_id}/pages/{page_id}\" # Correct format for currentPage\n",
        "\n",
        "    text_input = dialogflow.TextInput(text=text)\n",
        "    query_input = dialogflow.QueryInput(\n",
        "        text=text_input,\n",
        "        language_code=language_code\n",
        "        # Remove context_paths as it's not the correct way to specify the starting page\n",
        "    )\n",
        "    query_parameters = dialogflow.QueryParameters(\n",
        "        current_page=current_page_path # Specify the starting page using currentPage\n",
        "    )\n",
        "\n",
        "    # No need for try-except here because @retry handles exceptions\n",
        "    response = sessions_client.match_intent(\n",
        "        request={\n",
        "            \"session\": session_path,\n",
        "            \"query_input\": query_input,\n",
        "            \"query_params\": query_parameters\n",
        "        },\n",
        "        timeout=timeout # Add timeout\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Define the Pydantic schema for the Gemini output\n",
        "class IntentSuggestions(BaseModel):\n",
        "    analysis: str = Field(description=\"Detailed analysis of the intent and suggestions for improvement.\")\n",
        "    phrases_to_remove: list[int] = Field(description=\"List of training phrase indices to remove.\")\n",
        "    phrases_to_add: list[str] = Field(description=\"List of new training phrases to add, including parameter annotations in the form [parameter text](parameter_id) with 'parameter text' included in the list of entities or their synonym of the entity type corresponding to the parameter and parameter_id matching one of the existing parameters of the intent.\")\n",
        "\n",
        "\n",
        "# Function to get intent details\n",
        "def get_intent_details(intent_uuid, intents, entity_types):\n",
        "    intent = next((intent for intent in intents if intent.name.split('/')[-1] == intent_uuid), None)\n",
        "    if not intent:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    display_name = intent.display_name\n",
        "    description = intent.description\n",
        "\n",
        "    training_phrases = []\n",
        "    for tp in intent.training_phrases:\n",
        "        phrase_str = \"\"\n",
        "        for part in tp.parts:\n",
        "            if part.parameter_id:\n",
        "                phrase_str += f\"[{part.text}]({part.parameter_id})\"\n",
        "            else:\n",
        "                phrase_str += part.text\n",
        "        training_phrases.append(phrase_str)\n",
        "\n",
        "    parameters = []\n",
        "    for p in intent.parameters:\n",
        "        parameters.append({\n",
        "            \"id\": p.id,\n",
        "            \"entity_type\": p.entity_type.split('/')[-1]\n",
        "        })\n",
        "\n",
        "    # Extract entity types mentioned in training phrases\n",
        "    mentioned_entity_types_details = []\n",
        "    for parameter in intent.parameters:\n",
        "        entity_type_name = parameter.entity_type.split('/')[-1]\n",
        "        entity_type_obj = next((et for et in entity_types if et.name.split('/')[-1] == entity_type_name), None)\n",
        "        if entity_type_obj:\n",
        "            entities_with_synonyms = []\n",
        "            for entity in entity_type_obj.entities:\n",
        "                entities_with_synonyms.append(f\"{entity.value}: {', '.join(entity.synonyms)}\")\n",
        "            mentioned_entity_types_details.append({\n",
        "                \"parameter_id\": parameter.id,\n",
        "                \"display_name\": entity_type_obj.display_name,\n",
        "                \"entities\": entities_with_synonyms\n",
        "            })\n",
        "\n",
        "    return display_name, description, training_phrases, parameters, mentioned_entity_types_details\n",
        "\n",
        "\n",
        "def analyze_intent_with_gemini(intent_uuid, sentences, evaluation_results, intents, entity_types, language):\n",
        "    display_name, description, training_phrases, parameters, entities_details = get_intent_details(intent_uuid, intents, entity_types)\n",
        "\n",
        "    if not display_name:\n",
        "        print(f\"Could not find intent with UUID: {intent_uuid}. Skipping.\")\n",
        "        return intent_uuid, None\n",
        "\n",
        "    # Get relevant evaluation results for this intent's training sentences\n",
        "    relevant_eval_results = {sentence: result for sentence, result in evaluation_results.items() if result['expected_intent_uuid'] == intent_uuid and sentence in sentences}\n",
        "\n",
        "    training_phrases_string = \"\"\n",
        "    for i, phrase in enumerate(training_phrases):\n",
        "        training_phrases_string += f\"{i}: {phrase}\\n\"\n",
        "\n",
        "    all_entities_details = entities_details[:]\n",
        "    # Prepare the prompt for Gemini\n",
        "    prompt = f\"\"\"You are an expert NLU analyst tasked with optimizing an intent within a BERT-based Natural Language Understanding (NLU) system.\n",
        "\n",
        "Model Context: Because this is a BERT-based model, it relies on deep contextual understanding, sentence structure, and semantic relationships (embeddings), rather than simple keyword matching. Your goal is to refine the training data to sharpen the semantic boundaries of the target intent, improving its precision and recall (F1 score), and reducing confusion with other intents.\n",
        "\n",
        "Some training phrases may contain intentional spelling or grammar errors to capture ASR (Automatic Speech Recognition) transcription errors.\n",
        "\n",
        "Analyze the following intent and related data and provide concrete recommendations.\n",
        "\n",
        "## Analysis Objectives\n",
        "\n",
        "1.  **Identify Weaknesses & Coverage Gaps:** Determine why the target intent is not matching correctly. Is the training data too narrow (poor recall), too broad (poor precision), lacking variety, or failing to cover the scope defined in the description?\n",
        "2.  **Analyze Overlaps (Confusion Analysis):** For each Alternative Matched Intent, explain the *root cause* of the confusion. Focus on semantic similarities, shared vocabulary, or ambiguous training phrases in the Target Intent that cause the BERT model to struggle with differentiation.\n",
        "3.  **Entity Analysis:** Analyze if the existing entity types are being used effectively. You may suggest changes to the entity type definitions in the analysis, but recommendations (ADD/REMOVE) must use the entity types as they currently exist.\n",
        "\n",
        "## Recommendation Guidelines\n",
        "\n",
        "Your recommendations (ADD/REMOVE) must adhere strictly to these rules:\n",
        "\n",
        "1.  **Scope Management:** Do **not** expand the scope of the Target Intent beyond its description. Recommendations should only sharpen the existing scope and reduce ambiguity.\n",
        "2.  **Entity Constraints:** You must **not** add new entities or entity types in the training phrases. All new training phrases must only use the provided Mentioned Entity Types.\n",
        "3.  **Language Requirements:** **Crucial:** All analysis, explanations, and suggested training phrases must be in **{language}**.\n",
        "4.  **Natural Language and Stop Words (Crucial for BERT):**\n",
        "    *   Prioritize natural, idiomatic, conversational **{language}**.\n",
        "    *   **Include common {language} stop words** (articles, possessive pronouns, prepositions) where they are essential for a natural-sounding, grammatically correct utterance. BERT requires these for contextual understanding.\n",
        "    *   Avoid *unnecessary* filler words (e.g., \"umm,\" \"please\"), but do not strip necessary stop words.\n",
        "5.  **Handling Existing Errors:** Training phrases in the existing dataset that contain only one word, incomplete words, transcription errors (ASR), or spelling/grammar mistakes must **not** be marked for removal (they provide robustness), unless they are the direct cause of severe, unresolvable cross-intent confusion. You may ADD the corrected or more complete versions of these phrases.\n",
        "6.  **Quantity Guideline:** If the intent already has a large number of phrases (e.g., >100), be highly selective with ADD recommendations, focusing only on phrases that resolve specific overlaps or critical gaps.\n",
        "\n",
        "## Recommendation Types\n",
        "\n",
        "*   **ADD:**\n",
        "    *   Suggest new phrases that specifically help disambiguate the Target Intent from the Alternative Matched Intents.\n",
        "    *   Increase variety in sentence structure (questions, commands, statements) and coverage of real-world user expressions *within the scope*.\n",
        "    *   Explain the rationale for the addition.\n",
        "*   **REMOVE:**\n",
        "    *   Identify phrases (by index) that are highly ambiguous, out of scope, or directly cause unresolvable confusion with Alternative Matched Intents.\n",
        "    *   Explain the rationale for removal.\n",
        "    *   *Note: To update a phrase, you must REMOVE the old index and ADD the new version.*\n",
        "\n",
        "# Intent to Analyze\n",
        "\n",
        "Intent Display Name: {display_name}\n",
        "Description: {description}\n",
        "Parameters: {parameters}\n",
        "Training Phrases (with parameter annotations):\n",
        "{training_phrases_string}\n",
        "\n",
        "# Test Sentences and Matching Results (from evaluation):\n",
        "\"\"\"\n",
        "    if relevant_eval_results:\n",
        "        for sentence, result in relevant_eval_results.items():\n",
        "            prompt += f\"\"\"\n",
        "Sentence: {sentence}\n",
        "Expected Intent: {display_name}\n",
        "Matched Intent: {result['matched_intent_display_name']}\n",
        "Matched Intent Confidence: {result['matched_intent_confidence']}\n",
        "\"\"\"\n",
        "            if result['alternative_matches']:\n",
        "                for i, alt_match in enumerate(result['alternative_matches']):\n",
        "                    prompt += f\"Alternative Match #{i+1}: {alt_match['display_name']} (Confidence: {alt_match['confidence']})\\n\"\n",
        "\n",
        "    else:\n",
        "        prompt += \"No relevant evaluation results found for this intent in the training data.\\n\"\n",
        "\n",
        "    current_tokens = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=prompt).total_tokens\n",
        "\n",
        "    # Collect and deduplicate alternative intents\n",
        "    alternative_intents_info = {}\n",
        "    if relevant_eval_results:\n",
        "        for result in relevant_eval_results.values():\n",
        "            for alt_match in result.get('alternative_matches', []):\n",
        "                alt_intent_uuid = alt_match.get('intent_id')\n",
        "                if alt_intent_uuid and alt_intent_uuid != intent_uuid and alt_intent_uuid not in alternative_intents_info:\n",
        "                    alt_display_name, alt_description, alt_training_phrases, alt_parameters, alt_entities_details = get_intent_details(alt_intent_uuid, intents, entity_types)\n",
        "                    if alt_display_name:\n",
        "                        all_entities_details.extend(alt_entities_details)\n",
        "                        alt_training_phrases_string = \"\"\n",
        "                        for phrase in alt_training_phrases:\n",
        "                            alt_training_phrases_string += f\"- {phrase}\\n\"\n",
        "                        alternative_intents_info[alt_intent_uuid] = {\n",
        "                            \"display_name\": alt_display_name,\n",
        "                            \"description\": alt_description,\n",
        "                            \"parameters\": alt_parameters,\n",
        "                            \"training_phrases\": alt_training_phrases_string\n",
        "                        }\n",
        "\n",
        "    if alternative_intents_info:\n",
        "        prompt += \"\\n# Overlapping Intents\\n\"\n",
        "        for alt_intent_uuid, alt_info in alternative_intents_info.items():\n",
        "            alternative_intent_prompt = f\"\\nAlternative Matched Intent Display Name: ({alt_info['display_name']})\\n\"\n",
        "            alternative_intent_prompt += f\"Alternative Matched Description: {alt_info['description']}\\n\"\n",
        "            alternative_intent_prompt += f\"Alternative Matched Parameters: {alt_info['parameters']}\\n\"\n",
        "            alternative_intent_prompt += f\"Alternative Matched Training Phrases:\\n{alt_info['training_phrases']}\"\n",
        "            alternative_intent_token_count = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=alternative_intent_prompt).total_tokens\n",
        "            if current_tokens + alternative_intent_token_count > MAX_TOKEN_COUNT:\n",
        "                break\n",
        "            else:\n",
        "                current_tokens += alternative_intent_token_count\n",
        "                prompt += alternative_intent_prompt\n",
        "\n",
        "\n",
        "    # Deduplicate and add entities information\n",
        "    unique_entities = {v['display_name']:v for v in all_entities_details}.values()\n",
        "    if unique_entities:\n",
        "        prompt += \"\\n# Entity Types and Entities used in training phrases:\\n\"\n",
        "        for entity_detail in unique_entities:\n",
        "            entities_string = f\"\\nParameter ID: {entity_detail['parameter_id']}\\nEntity Type: {entity_detail['display_name']}\\nEntities:\\n\"\n",
        "            for entity in entity_detail['entities']:\n",
        "                entities_string += f\"- {entity}\\n\"\n",
        "            entities_token_count = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=entities_string).total_tokens\n",
        "            if current_tokens + entities_token_count > MAX_TOKEN_COUNT:\n",
        "                break\n",
        "            else:\n",
        "                prompt += entities_string\n",
        "                current_tokens += entities_token_count\n",
        "\n",
        "    try:\n",
        "        # Call Gemini API\n",
        "        response = genai_client.models.generate_content(\n",
        "            model=GEMINI_MODEL,\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                response_mime_type='application/json',\n",
        "                response_schema=IntentSuggestions,\n",
        "            )\n",
        "        )\n",
        "        return intent_uuid, response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing intent {display_name} ({intent_uuid}): {e}\")\n",
        "        return intent_uuid, f\"Error generating suggestions for intent {display_name}: {e}\"\n",
        "\n",
        "\n",
        "def analyze_intents_with_gemini(current_train_sentences, evaluation_results, intents, entity_types, language):\n",
        "    gemini_suggestions = {}\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        future_to_intent = {\n",
        "            executor.submit(\n",
        "                analyze_intent_with_gemini,\n",
        "                intent_uuid,\n",
        "                sentences,\n",
        "                evaluation_results,\n",
        "                intents,\n",
        "                entity_types,\n",
        "                language\n",
        "            ): intent_uuid\n",
        "            for intent_uuid, sentences in current_train_sentences.items()\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(future_to_intent), total=len(future_to_intent), desc=\"Analyzing Intents with Gemini\"):\n",
        "            intent_uuid, suggestions = future.result()\n",
        "            if suggestions:\n",
        "                gemini_suggestions[intent_uuid] = suggestions\n",
        "\n",
        "    return gemini_suggestions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8c297a4"
      },
      "source": [
        "# @title Reinforcement Learning Loop\n",
        "\n",
        "def evaluate_sentences(sentences_to_evaluate, agent_name, session_id, flow_id, page_id, language_code):\n",
        "    \"\"\"Evaluates a set of test sentences and returns the results and accuracy.\"\"\"\n",
        "    evaluation_results = {}\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        future_to_sentence_eval = {\n",
        "            executor.submit(match_intent, agent_name, sentence, session_id, flow_id, page_id, language_code): (sentence, intent_uuid)\n",
        "            for intent_uuid, sentences in sentences_to_evaluate.items() for sentence in sentences\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(future_to_sentence_eval), total=len(future_to_sentence_eval), desc=\"Evaluating Sentences\"):\n",
        "            sentence, expected_intent_uuid = future_to_sentence_eval[future]\n",
        "            total_predictions += 1\n",
        "            try:\n",
        "                response = future.result()\n",
        "                if response and response.matches:\n",
        "                    matched_intent_id = response.matches[0].intent.name.split('/')[-1]\n",
        "                    matched_intent_display_name = response.matches[0].intent.display_name\n",
        "                    matched_intent_confidence = response.matches[0].confidence\n",
        "                    alternative_matches = [\n",
        "                        {\"intent_id\": m.intent.name.split('/')[-1], \"display_name\": m.intent.display_name, \"confidence\": m.confidence}\n",
        "                        for m in response.matches[1:]\n",
        "                    ]\n",
        "                    evaluation_results[sentence] = {\n",
        "                        \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                        \"matched_intent_uuid\": matched_intent_id,\n",
        "                        \"matched_intent_display_name\": matched_intent_display_name,\n",
        "                        \"matched_intent_confidence\": matched_intent_confidence,\n",
        "                        \"alternative_matches\": alternative_matches\n",
        "                    }\n",
        "                    if matched_intent_id == expected_intent_uuid:\n",
        "                        correct_predictions += 1\n",
        "                else:\n",
        "                    evaluation_results[sentence] = {\n",
        "                        \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                        \"matched_intent_uuid\": \"No match\",\n",
        "                        \"matched_intent_display_name\": \"No match\",\n",
        "                        \"matched_intent_confidence\": 0.0,\n",
        "                        \"alternative_matches\": []\n",
        "                    }\n",
        "            except Exception as exc:\n",
        "                evaluation_results[sentence] = {\n",
        "                    \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                    \"matched_intent_uuid\": \"No match\",\n",
        "                    \"matched_intent_display_name\": \"No match\",\n",
        "                    \"matched_intent_confidence\": 0.0,\n",
        "                    \"alternative_matches\": []\n",
        "                }\n",
        "                print(f\"Evaluation sentence '{sentence}' generated an exception: {exc}\")\n",
        "\n",
        "    accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
        "    return evaluation_results, accuracy\n",
        "\n",
        "\n",
        "# --- Baseline Evaluation ---\n",
        "print(\"--- Running Baseline Evaluation ---\")\n",
        "baseline_session_id = f\"baseline-eval-{uuid.uuid4()}\"\n",
        "baseline_test_evaluation_results, baseline_test_accuracy = evaluate_sentences(test_sentences, agent.name, baseline_session_id, FLOW_ID, PAGE_ID, LANGUAGE_CODE)\n",
        "print(f\"\\nBaseline Accuracy Test: {baseline_test_accuracy:.2f}%\")\n",
        "baseline_train_evaluation_results, baseline_train_accuracy = evaluate_sentences(train_sentences, agent.name, baseline_session_id, FLOW_ID, PAGE_ID, LANGUAGE_CODE)\n",
        "print(f\"\\nBaseline Accuracy Train: {baseline_train_accuracy:.2f}%\")\n",
        "\n",
        "test_accuracies = [baseline_test_accuracy]\n",
        "train_accuracies = [baseline_train_accuracy]\n",
        "all_gemini_suggestions = {}\n",
        "\n",
        "for i in range(REINFORCEMENT_ITERATIONS):\n",
        "    print(f\"\\n--- Starting Reinforcement Iteration {i+1}/{REINFORCEMENT_ITERATIONS} ---\")\n",
        "\n",
        "    # 1. Identify problematic intents in the train set\n",
        "    problematic_intent_uuids = set()\n",
        "    current_train_evaluation_results = baseline_train_evaluation_results if i == 0 else train_evaluation_results\n",
        "    for sentence, result in current_train_evaluation_results.items():\n",
        "        if result['matched_intent_uuid'] != result['expected_intent_uuid']:\n",
        "            problematic_intent_uuids.add(result['expected_intent_uuid'])\n",
        "            problematic_intent_uuids.add(result['matched_intent_uuid'])\n",
        "        if result['alternative_matches']:\n",
        "            for alternative_match in result['alternative_matches']:\n",
        "                confidence_difference = result['matched_intent_confidence'] - alternative_match['confidence']\n",
        "                if confidence_difference < REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE:\n",
        "                    problematic_intent_uuids.add(result['matched_intent_uuid'])\n",
        "                    problematic_intent_uuids.add(alternative_match['intent_id'])\n",
        "\n",
        "    if not problematic_intent_uuids:\n",
        "        print(\"No problematic intents found. Stopping reinforcement learning.\")\n",
        "        break\n",
        "\n",
        "    print(f\"Found {len(problematic_intent_uuids)} problematic intents to analyze.\")\n",
        "\n",
        "    # Create a dictionary of the problematic sentences to pass to Gemini\n",
        "    problematic_sentences_for_gemini = {}\n",
        "    for intent_uuid in problematic_intent_uuids:\n",
        "        if intent_uuid in train_sentences:\n",
        "            problematic_sentences_for_gemini[intent_uuid] = train_sentences[intent_uuid]\n",
        "\n",
        "\n",
        "    # 2. Analyze with Gemini\n",
        "    gemini_suggestions = analyze_intents_with_gemini(\n",
        "        problematic_sentences_for_gemini,\n",
        "        current_train_evaluation_results,\n",
        "        intents,\n",
        "        entity_types,\n",
        "        language\n",
        "    )\n",
        "    # Store Gemini's suggestions for the report\n",
        "    for intent_uuid, suggestions in gemini_suggestions.items():\n",
        "        if intent_uuid not in all_gemini_suggestions:\n",
        "            all_gemini_suggestions[intent_uuid] = []\n",
        "        all_gemini_suggestions[intent_uuid].append(suggestions)\n",
        "\n",
        "    # 3. Apply Gemini's suggestions\n",
        "    @retry.Retry(\n",
        "        initial=60,\n",
        "        maximum=300,\n",
        "        timeout=600,\n",
        "    )\n",
        "    def update_intent_with_retry(intent_to_update):\n",
        "      intents_client.update_intent(intent=intent_to_update)\n",
        "\n",
        "    for intent_uuid, suggestions_json in tqdm(gemini_suggestions.items(), desc=\"Applying Gemini Suggestions\"):\n",
        "        if suggestions_json.startswith(\"Error generating suggestions:\"):\n",
        "            tqdm.write(f\"Skipping intent {intent_uuid} due to generation error: {suggestions_json}\")\n",
        "            continue\n",
        "        try:\n",
        "            suggestions = IntentSuggestions.model_validate_json(suggestions_json)\n",
        "            intent_to_update = next((intent for intent in intents if intent.name.split('/')[-1] == intent_uuid), None)\n",
        "\n",
        "            if not intent_to_update:\n",
        "                tqdm.write(f\"Could not find intent with UUID: {intent_uuid} to apply suggestions. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            tqdm.write(f\"\\nApplying suggestions for intent: {intent_to_update.display_name}\")\n",
        "\n",
        "            # Remove phrases\n",
        "            phrases_to_remove_indices = sorted(suggestions.phrases_to_remove, reverse=True)\n",
        "            if phrases_to_remove_indices:\n",
        "                tqdm.write(f\"Removing {len(phrases_to_remove_indices)} phrases...\")\n",
        "                for index in phrases_to_remove_indices:\n",
        "                    if 0 <= index < len(intent_to_update.training_phrases):\n",
        "                        del intent_to_update.training_phrases[index]\n",
        "\n",
        "            # Add phrases\n",
        "            if suggestions.phrases_to_add:\n",
        "                tqdm.write(f\"Adding {len(suggestions.phrases_to_add)} new phrases...\")\n",
        "                for phrase_text in suggestions.phrases_to_add:\n",
        "                    # Check for duplicates before adding\n",
        "                    if any(phrase_text == \"\".join([p.text for p in tp.parts]) for tp in intent_to_update.training_phrases):\n",
        "                        tqdm.write(f\"Skipping duplicate phrase: {phrase_text}\")\n",
        "                        continue\n",
        "\n",
        "                    new_training_phrase = dialogflow.Intent.TrainingPhrase(repeat_count=1)\n",
        "                    parts = re.split(r'(\\[[^\\]]+\\]\\([^\\)]+\\))', phrase_text)\n",
        "                    skip_phrase = False\n",
        "                    for part in parts:\n",
        "                        match = re.match(r'\\[([^\\]]+)\\]\\(([^\\)]+)\\)', part)\n",
        "                        if match:\n",
        "                            parameter_id = match.group(2)\n",
        "                            if not any(p.id == parameter_id for p in intent_to_update.parameters):\n",
        "                                tqdm.write(f\"Skipping phrase with undefined parameter: {phrase_text}\")\n",
        "                                skip_phrase = True\n",
        "                                break\n",
        "                    if skip_phrase:\n",
        "                        continue\n",
        "\n",
        "                    for part in parts:\n",
        "                        match = re.match(r'\\[([^\\]]+)\\]\\(([^\\)]+)\\)', part)\n",
        "                        if match:\n",
        "                            text = match.group(1)\n",
        "                            parameter_id = match.group(2)\n",
        "                            new_training_phrase.parts.append(dialogflow.Intent.TrainingPhrase.Part(text=text, parameter_id=parameter_id))\n",
        "                        elif part:\n",
        "                            new_training_phrase.parts.append(dialogflow.Intent.TrainingPhrase.Part(text=part))\n",
        "                    intent_to_update.training_phrases.append(new_training_phrase)\n",
        "\n",
        "            # Ensure all training phrases have repeat_count\n",
        "            for tp in intent_to_update.training_phrases:\n",
        "                if not 'repeat_count' in tp or not tp.repeat_count or tp.repeat_count < 1:\n",
        "                    tp.repeat_count = 1\n",
        "\n",
        "            # Update the intent\n",
        "            update_intent_with_retry(intent_to_update)\n",
        "            tqdm.write(f\"Successfully updated intent: {intent_to_update.display_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error applying suggestions for intent {intent_uuid}: {e}\")\n",
        "            raise e\n",
        "\n",
        "    # 4. Train the flow\n",
        "    print(\"\\nTraining the flow...\")\n",
        "    operation = flows_client.train_flow(name=flow.name)\n",
        "    print(\"Waiting for training to complete...\")\n",
        "    operation.result(timeout=7200)\n",
        "    print(\"Flow training completed successfully.\")\n",
        "\n",
        "\n",
        "    # 5. Re-evaluate all test sentences\n",
        "    print(\"\\nRe-evaluating all sentences after applying suggestions...\")\n",
        "    session_id = f\"re-eval-{i+1}-{uuid.uuid4()}\"\n",
        "    test_evaluation_results, test_accuracy = evaluate_sentences(test_sentences, agent.name, session_id, FLOW_ID, PAGE_ID, LANGUAGE_CODE)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_evaluation_results, train_accuracy = evaluate_sentences(train_sentences, agent.name, session_id, FLOW_ID, PAGE_ID, LANGUAGE_CODE)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "    # 6. Calculate and print improvement summary for the iteration\n",
        "    print(f\"\\n--- Iteration {i+1} Summary ---\")\n",
        "    print(f\"Baseline Test Accuracy: {test_accuracies[0]:.2f}%\")\n",
        "    for j, acc in enumerate(test_accuracies[1:]):\n",
        "        print(f\"Test Accuracy after Iteration {j+1}: {acc:.2f}%\")\n",
        "    print(f\"Baseline Train Accuracy: {train_accuracies[0]:.2f}%\")\n",
        "    for j, acc in enumerate(train_accuracies[1:]):\n",
        "        print(f\"Train Accuracy after Iteration {j+1}: {acc:.2f}%\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Reinforcement Learning Finished ---\")\n",
        "\n",
        "final_test_evaluation_results = test_evaluation_results\n",
        "final_train_evaluation_results = train_evaluation_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb4a0789"
      },
      "source": [
        "## Final Report and Summary\n",
        "\n",
        "This report summarizes the results of the reinforcement learning process. It includes an analysis of the initial and final evaluation results, a summary of the changes made by Gemini, and recommendations for further improvements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55862731"
      },
      "source": [
        "# @title Generate Final Report and Download Excel\n",
        "\n",
        "!pip install XlsxWriter\n",
        "\n",
        "def generate_final_report_excel(initial_test_results, final_test_results, initial_train_results, final_train_results, all_gemini_suggestions, intents):\n",
        "    \"\"\"Generates a final report in an Excel file and returns a summary HTML table.\"\"\"\n",
        "\n",
        "    # --- Create Excel Writer ---\n",
        "    excel_writer = pd.ExcelWriter('final_report.xlsx', engine='xlsxwriter')\n",
        "\n",
        "    # --- Overall Summary Data ---\n",
        "    summary_data = []\n",
        "    for data_type, initial_results, final_results in [\n",
        "        (\"Test\", initial_test_results, final_test_results),\n",
        "        (\"Train\", initial_train_results, final_train_results)\n",
        "    ]:\n",
        "        initial_correct = sum(1 for r in initial_results.values() if r['matched_intent_uuid'] == r['expected_intent_uuid'])\n",
        "        final_correct = sum(1 for r in final_results.values() if r['matched_intent_uuid'] == r['expected_intent_uuid'])\n",
        "        total_sentences = len(initial_results)\n",
        "        initial_accuracy = (initial_correct / total_sentences) * 100 if total_sentences > 0 else 0\n",
        "        final_accuracy = (final_correct / total_sentences) * 100 if total_sentences > 0 else 0\n",
        "        summary_data.append({\n",
        "            \"Data Type\": data_type,\n",
        "            \"Initial Correct\": initial_correct,\n",
        "            \"Final Correct\": final_correct,\n",
        "            \"Total Sentences\": total_sentences,\n",
        "            \"Initial Accuracy\": f\"{initial_accuracy:.2f}%\",\n",
        "            \"Final Accuracy\": f\"{final_accuracy:.2f}%\",\n",
        "            \"Improvement\": f\"{final_accuracy - initial_accuracy:.2f}%\"\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df.to_excel(excel_writer, sheet_name='Summary', index=False)\n",
        "\n",
        "    # --- Detailed Comparison Data ---\n",
        "    detailed_data = []\n",
        "    for sentence, initial_r in initial_test_results.items():\n",
        "        final_r = final_test_results.get(sentence, {})\n",
        "        initial_match_str = f\"{initial_r.get('matched_intent_display_name', 'N/A')} ({initial_r.get('matched_intent_confidence', 0):.2f})\"\n",
        "        final_match_str = f\"{final_r.get('matched_intent_display_name', 'N/A')} ({final_r.get('matched_intent_confidence', 0):.2f})\"\n",
        "        expected_intent_display_name = next((intent.display_name for intent in intents if intent.name.split('/')[-1] == initial_r['expected_intent_uuid']), \"Unknown Intent\")\n",
        "\n",
        "        status = \" Correct\"\n",
        "        if initial_r.get('matched_intent_uuid') != initial_r.get('expected_intent_uuid'):\n",
        "            if final_r.get('matched_intent_uuid') == final_r.get('expected_intent_uuid'):\n",
        "                status = \" Fixed\"\n",
        "            else:\n",
        "                status = \" Still Incorrect\"\n",
        "\n",
        "        if initial_r.get('matched_intent_uuid') != final_r.get('matched_intent_uuid') or status != \" Correct\":\n",
        "            detailed_data.append({\n",
        "                \"Sentence\": sentence,\n",
        "                \"Expected Intent\": expected_intent_display_name,\n",
        "                \"Initial Match (Confidence)\": initial_match_str,\n",
        "                \"Final Match (Confidence)\": final_match_str,\n",
        "                \"Status\": status\n",
        "            })\n",
        "\n",
        "    detailed_df = pd.DataFrame(detailed_data)\n",
        "    detailed_df.to_excel(excel_writer, sheet_name='Detailed Comparison', index=False)\n",
        "\n",
        "    # --- Gemini's Changes ---\n",
        "    gemini_changes_data = []\n",
        "    for intent_uuid, suggestions_list in all_gemini_suggestions.items():\n",
        "        intent_display_name = next((intent.display_name for intent in intents if intent.name.split('/')[-1] == intent_uuid), \"Unknown Intent\")\n",
        "        for i, suggestions_json in enumerate(suggestions_list):\n",
        "            try:\n",
        "                suggestions = IntentSuggestions.model_validate_json(suggestions_json)\n",
        "                gemini_changes_data.append({\n",
        "                    \"Intent\": f\"{intent_display_name} ({intent_uuid})\",\n",
        "                    \"Iteration\": i + 1,\n",
        "                    \"Analysis\": suggestions.analysis,\n",
        "                    \"Added Phrases\": \"\\n\".join(suggestions.phrases_to_add),\n",
        "                    \"Removed Phrase Indices\": \"\\n\".join(map(str, suggestions.phrases_to_remove))\n",
        "                })\n",
        "            except Exception as e:\n",
        "                gemini_changes_data.append({\n",
        "                    \"Intent\": f\"{intent_display_name} ({intent_uuid})\",\n",
        "                    \"Iteration\": i + 1,\n",
        "                    \"Analysis\": f\"Error parsing suggestions: {e}\",\n",
        "                    \"Added Phrases\": \"\",\n",
        "                    \"Removed Phrase Indices\": \"\"\n",
        "                })\n",
        "\n",
        "    gemini_df = pd.DataFrame(gemini_changes_data)\n",
        "    gemini_df.to_excel(excel_writer, sheet_name='Gemini Suggestions', index=False)\n",
        "\n",
        "    # --- Save Excel and Generate HTML ---\n",
        "    excel_writer.close()\n",
        "\n",
        "    # Return summary table as HTML\n",
        "    return summary_df.to_html(index=False, classes='table table-striped', justify='left')\n",
        "\n",
        "\n",
        "# --- Generate and Display Report ---\n",
        "final_report_html = generate_final_report_excel(\n",
        "    baseline_test_evaluation_results,\n",
        "    final_test_evaluation_results,\n",
        "    baseline_train_evaluation_results,\n",
        "    final_train_evaluation_results,\n",
        "    all_gemini_suggestions,\n",
        "    intents\n",
        ")\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "display(HTML(final_report_html))\n",
        "\n",
        "# --- Download Excel File ---\n",
        "from google.colab import files\n",
        "files.download('final_report.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}