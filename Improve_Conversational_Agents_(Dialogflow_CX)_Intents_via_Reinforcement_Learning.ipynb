{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsM3M80irje9rCTJqtLg0J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffeldhaus/conversational-agents-intent-improver-agent/blob/main/Improve_Conversational_Agents_(Dialogflow_CX)_Intents_via_Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPO7-dyafunE"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-dialogflow-cx google-genai tqdm langcodes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import io\n",
        "import re\n",
        "import uuid\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "from google.api_core import retry\n",
        "from google.api_core.client_options import ClientOptions\n",
        "\n",
        "from google.cloud import dialogflowcx_v3 as dialogflow\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from langcodes import Language"
      ],
      "metadata": {
        "id": "XJPlj7kWm9n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration { display-mode: \"form\" }\n",
        "\n",
        "AGENT_NAME = \"projects/ucds-testsystem/locations/europe-west3/agents/e444b62c-6b83-489b-b41c-373c62093972\" # @param {type:\"string\"}\n",
        "FLOW_ID = \"135bf7a3-7481-4e69-923b-f9dcfc4bec6e\" # @param {type:\"string\"}\n",
        "PAGE_ID = \"b9d110b1-d061-471a-a568-68f6198efcb3\" # @param {type:\"string\"}\n",
        "NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS = 0.0001 # @param {type:\"number\"}\n",
        "TEST_TRAIN_SPLIT_RATE = 0.95 # @param {type:\"number\"}\n",
        "REINFORCEMENT_ITERATIONS = 3 # @param {type:\"number\"}\n",
        "REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE = 0.2\n",
        "GEMINI_MODEL = \"gemini-2.5-pro\" # @param {type:\"string\"}\n",
        "LANGUAGE_CODE = \"\" # @param {type:\"string\"}\n",
        "MAX_TOKEN_COUNT = 1048575 # @param {type:\"integer\"}\n",
        "\n",
        "# Extract the project ID from the agent name\n",
        "project_id = AGENT_NAME.split('/')[1]\n",
        "# Extract the location from the agent name\n",
        "location = AGENT_NAME.split('/')[3]"
      ],
      "metadata": {
        "id": "SdrdoeMFgcg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Authenticate\n",
        "\n",
        "auth.authenticate_user(project_id=project_id)"
      ],
      "metadata": {
        "id": "0hOpiC_rn4nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize\n",
        "\n",
        "# Initialize genai Client for Gemini usage\n",
        "genai_client = genai.Client(\n",
        "    #vertexai=True, project=project_id, location=location\n",
        "    vertexai=True, project=project_id, location=\"europe-west4\"\n",
        ")\n",
        "\n",
        "# Initialize Dialogflow CX Clients with the correct endpoint\n",
        "\n",
        "if location != \"global\":\n",
        "  api_endpoint=f\"{location}-dialogflow.googleapis.com\"\n",
        "else:\n",
        "  api_endpoint=f\"dialogflow.googleapis.com\"\n",
        "\n",
        "client_options = ClientOptions(api_endpoint=api_endpoint)\n",
        "agents_client = dialogflow.AgentsClient(client_options=client_options)\n",
        "flows_client = dialogflow.FlowsClient(client_options=client_options)\n",
        "pages_client = dialogflow.PagesClient(client_options=client_options)\n",
        "intents_client = dialogflow.IntentsClient(client_options=client_options)\n",
        "entity_types_client = dialogflow.EntityTypesClient(client_options=client_options)\n",
        "sessions_client = dialogflow.SessionsClient(client_options=client_options)"
      ],
      "metadata": {
        "id": "z49rhwmk-k8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Get Dialogflow CX resources\n",
        "\n",
        "# Read the agent\n",
        "agent = agents_client.get_agent(name=AGENT_NAME)\n",
        "print(f\"Agent read successfully: {agent.display_name}\")\n",
        "\n",
        "# fallback to default language code\n",
        "if not LANGUAGE_CODE:\n",
        "  LANGUAGE_CODE = agent.default_language_code\n",
        "\n",
        "# get language name\n",
        "language = Language.get(LANGUAGE_CODE).language_name(\"en\")\n",
        "print(f\"Using Language: {language} ({LANGUAGE_CODE})\")\n",
        "\n",
        "# Get Flow\n",
        "flow = flows_client.get_flow(name=f\"{AGENT_NAME}/flows/{FLOW_ID}\")\n",
        "print(f\"Flow read successfully: {flow.display_name}\")\n",
        "\n",
        "# Get Page\n",
        "page = pages_client.get_page(name=f\"{AGENT_NAME}/flows/{FLOW_ID}/pages/{PAGE_ID}\")\n",
        "print(f\"Page read successfully: {page.display_name}\")\n",
        "\n",
        "# Get Intents\n",
        "intents = list(intents_client.list_intents(parent=AGENT_NAME))\n",
        "print(f\"Intents read successfully: {len(intents)}\")\n",
        "\n",
        "# Get Entity Types\n",
        "entity_types = list(entity_types_client.list_entity_types(parent=AGENT_NAME))\n",
        "print(f\"Entity types read successfully: {len(entity_types)}\")"
      ],
      "metadata": {
        "id": "ctbAQ-G5mNyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Check and update NLU threshold and training mode for the flow\n",
        "\n",
        "if NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS != 0 and flow.nlu_settings.classification_threshold != NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS:\n",
        "    flow.nlu_settings.classification_threshold = NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS\n",
        "    flows_client.update_flow(request={\"flow\": flow})\n",
        "    print(f\"NLU threshold updated for flow {flow.display_name} to {NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS}\")\n",
        "else:\n",
        "    print(f\"NLU threshold for flow {flow.display_name} is already {flow.nlu_settings.classification_threshold} or NLU_THRESHOLD_ALTERNATIVE_MATCHING_INTENTS is 0. No update needed.\")\n",
        "\n",
        "if flow.nlu_settings.model_training_mode != dialogflow.types.NluSettings.ModelTrainingMode.MODEL_TRAINING_MODE_MANUAL:\n",
        "    flow.nlu_settings.model_training_mode = dialogflow.types.NluSettings.ModelTrainingMode.MODEL_TRAINING_MODE_MANUAL\n",
        "    flows_client.update_flow(request={\"flow\": flow})\n",
        "    print(f\"Training mode updated for flow {flow.display_name} to MANUAL\")\n",
        "else:\n",
        "    print(f\"Training mode for flow {flow.display_name} is already MANUAL. No update needed.\")"
      ],
      "metadata": {
        "id": "goV6Yy2RsEor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload XLSX or CSV file(s) with test sentences and matching intents\n",
        "\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "test_sentences = {}\n",
        "\n",
        "# Create a dictionary to map intent display names to UUIDs\n",
        "intent_display_name_to_uuid = {intent.display_name: intent.name.split('/')[-1] for intent in intents}\n",
        "\n",
        "for file_name, file_content in uploaded_files.items():\n",
        "    print(f\"Processing file: {file_name}\")\n",
        "    try:\n",
        "        if file_name.endswith('.csv'):\n",
        "            df = pd.read_csv(io.BytesIO(file_content), on_bad_lines='warn')\n",
        "        elif file_name.endswith('.xlsx'):\n",
        "            df = pd.read_excel(io.BytesIO(file_content))\n",
        "        else:\n",
        "            print(f\"Skipping unsupported file type: {file_name}\")\n",
        "            continue\n",
        "\n",
        "        # Assume the first row is header and the data starts from the second row\n",
        "        # Rename columns for easier access\n",
        "        df.columns = ['Intent', 'Test']\n",
        "\n",
        "\n",
        "        # Process data: Assume column 1 is intent, column 2 is test sentence\n",
        "        for index, row in df.iterrows():\n",
        "            intent_from_file = str(row['Intent']).strip()\n",
        "            sentence = str(row['Test']).strip()\n",
        "\n",
        "            if not sentence: # Skip if sentence is empty\n",
        "                continue\n",
        "\n",
        "            # Check if intent is a UUID\n",
        "            if re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', intent_from_file):\n",
        "                intent_uuid = intent_from_file\n",
        "            # Check if intent is a display name and exists in the agent's intents\n",
        "            elif intent_from_file in intent_display_name_to_uuid:\n",
        "                intent_uuid = intent_display_name_to_uuid[intent_from_file]\n",
        "            else:\n",
        "                print(f\"Ignoring row {index} in {file_name}: Invalid intent '{intent_from_file}'. Not a valid UUID or a known display name.\")\n",
        "                continue\n",
        "\n",
        "            if intent_uuid not in test_sentences:\n",
        "                test_sentences[intent_uuid] = []\n",
        "            test_sentences[intent_uuid].append(sentence)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "print(f\"\\nProcessed {len(test_sentences)} intents with a total of {sum(len(sentences) for sentences in test_sentences.values())} test sentences.\")"
      ],
      "metadata": {
        "id": "5VU24vHJg3ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function to match intent for a given text\n",
        "\n",
        "@retry.Retry()\n",
        "def match_intent(project_id, location, agent_id, text, session_id, flow_id, page_id, timeout=10):\n",
        "    \"\"\"Returns the result of detect intent with texts as inputs.\n",
        "\n",
        "    Using the same `session_id` between requests allows continuation of the conversation.\"\"\"\n",
        "    agent = f\"projects/{project_id}/locations/{location}/agents/{agent_id}\"\n",
        "    session_path = f\"{agent}/sessions/{session_id}\"\n",
        "    current_page_path = f\"{agent}/flows/{flow_id}/pages/{page_id}\" # Correct format for currentPage\n",
        "\n",
        "    text_input = dialogflow.TextInput(text=text)\n",
        "    query_input = dialogflow.QueryInput(\n",
        "        text=text_input,\n",
        "        language_code=\"en-US\"\n",
        "        # Remove context_paths as it's not the correct way to specify the starting page\n",
        "    )\n",
        "    query_parameters = dialogflow.QueryParameters(\n",
        "        current_page=current_page_path # Specify the starting page using currentPage\n",
        "    )\n",
        "\n",
        "    # No need for try-except here because @retry handles exceptions\n",
        "    response = sessions_client.match_intent(\n",
        "        request={\n",
        "            \"session\": session_path,\n",
        "            \"query_input\": query_input,\n",
        "            \"query_params\": query_parameters\n",
        "        },\n",
        "        timeout=timeout # Add timeout\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "-E9-F5cB40ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop automatic execution here as the following cells are very experimental"
      ],
      "metadata": {
        "id": "KrGbW9WCwMJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37abcf41"
      },
      "source": [
        "# Task\n",
        "Implement Reinforcement Learning using gemini to analyze an intent, intent description, intent training phrases, entities mentioned in the intent and have Gemini make suggestions what to improve to increase the intent matching rate of the test data. Gemini should understand that the Intent matching is done using a BERT NLU trained specifically with the Intent Training Phrases and Entities. Ensure that only a split of the test data is used and always the same (e.g. for split 0.3 use the first 3 for verification only and the later 7 for reinforcement learning and verification). The recommendations should be applied and retested. Then gemini should analyze the results and improvements and make further suggestions, up to REINFORCEMENT_ITERATIONS iterations. Ultimately a report should be generated on what improvements where achieved and guidance on what additionally could / should be changed for further improvements. To call Gemini only use the model name without a project or path, e.g. \"gemini-2.5-pro\" the project and location where already specified during client initialization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e330240e"
      },
      "source": [
        "## Split test data\n",
        "\n",
        "### Subtask:\n",
        "Split the `test_sentences` data into training and testing sets based on the `TEST_TRAIN_SPLIT_RATE`. The training set will be used for reinforcement learning with Gemini, and the testing set will be used for final evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb660ad8"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary function and split the data into training and testing sets, then convert them back to the required dictionary format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d622e437"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert the test_sentences dictionary into a list of tuples\n",
        "test_sentences_list = []\n",
        "for intent_uuid, sentences in test_sentences.items():\n",
        "    for sentence in sentences:\n",
        "        test_sentences_list.append((sentence, intent_uuid))\n",
        "\n",
        "# Split the list into training and testing sets\n",
        "train_list, test_list = train_test_split(test_sentences_list, test_size=TEST_TRAIN_SPLIT_RATE, random_state=42)\n",
        "\n",
        "# Convert the resulting lists back into dictionaries\n",
        "train_sentences = {}\n",
        "for sentence, intent_uuid in train_list:\n",
        "    if intent_uuid not in train_sentences:\n",
        "        train_sentences[intent_uuid] = []\n",
        "    train_sentences[intent_uuid].append(sentence)\n",
        "\n",
        "test_sentences_eval = {}\n",
        "for sentence, intent_uuid in test_list:\n",
        "    if intent_uuid not in test_sentences_eval:\n",
        "        test_sentences_eval[intent_uuid] = []\n",
        "    test_sentences_eval[intent_uuid].append(sentence)\n",
        "\n",
        "print(f\"Total sentences: {len(test_sentences_list)}\")\n",
        "print(f\"Training sentences: {len(train_list)}\")\n",
        "print(f\"Testing sentences for evaluation: {len(test_list)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0babb0da"
      },
      "source": [
        "## Initial evaluation\n",
        "\n",
        "Evaluate all Test sentences as initial baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78300a67"
      },
      "source": [
        "# Initialize a dictionary to store the evaluation results\n",
        "evaluation_results = {}\n",
        "\n",
        "session_id = \"baseline-\" + str(uuid.uuid4())\n",
        "\n",
        "# Use ThreadPoolExecutor for parallel execution during evaluation\n",
        "with ThreadPoolExecutor(max_workers=10) as executor: # Adjust max_workers as needed\n",
        "    future_to_sentence_eval = {}\n",
        "    for intent_uuid, sentences in test_sentences.items():\n",
        "        for sentence in sentences:\n",
        "            future = executor.submit(\n",
        "                match_intent,\n",
        "                project_id,\n",
        "                location,\n",
        "                agent.name.split('/')[-1],\n",
        "                sentence,\n",
        "                session_id,\n",
        "                FLOW_ID, # Pass FLOW_ID\n",
        "                PAGE_ID # Pass PAGE_ID\n",
        "            )\n",
        "            future_to_sentence_eval[future] = (sentence, intent_uuid)\n",
        "\n",
        "    # Wrap as_completed with tqdm for a progress bar\n",
        "    for future in tqdm(as_completed(future_to_sentence_eval), total=len(future_to_sentence_eval), desc=\"Evaluating Sentences\"):\n",
        "        sentence, expected_intent_uuid = future_to_sentence_eval[future]\n",
        "        try:\n",
        "            response = future.result()\n",
        "\n",
        "            if response and response.matches:\n",
        "                matched_intent_id = response.matches[0].intent.name.split('/')[-1] if response.matches[0].intent else \"N/A\"\n",
        "                matched_intent_display_name = response.matches[0].intent.display_name if response.matches[0].intent else \"N/A\"\n",
        "                matched_intent_confidence = response.matches[0].confidence\n",
        "\n",
        "                alternative_matches = []\n",
        "                if len(response.matches) > 1:\n",
        "                     for i, match in enumerate(response.matches[1:]): # Start from the second match\n",
        "                        alternative_intent_id = match.intent.name.split('/')[-1] if match.intent else \"N/A\"\n",
        "                        alternative_intent_display_name = match.intent.display_name if match.intent else \"N/A\"\n",
        "                        alternative_intent_confidence = match.confidence\n",
        "                        alternative_matches.append({\n",
        "                            \"intent_id\": alternative_intent_id,\n",
        "                            \"display_name\": alternative_intent_display_name,\n",
        "                            \"confidence\": alternative_intent_confidence\n",
        "                        })\n",
        "\n",
        "                evaluation_results[sentence] = {\n",
        "                    \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                    \"matched_intent_uuid\": matched_intent_id,\n",
        "                    \"matched_intent_display_name\": matched_intent_display_name,\n",
        "                    \"matched_intent_confidence\": matched_intent_confidence,\n",
        "                    \"alternative_matches\": alternative_matches\n",
        "                }\n",
        "            else:\n",
        "                evaluation_results[sentence] = {\n",
        "                    \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                    \"matched_intent_uuid\": \"No match\",\n",
        "                    \"matched_intent_display_name\": \"No match\",\n",
        "                    \"matched_intent_confidence\": 0.0,\n",
        "                    \"alternative_matches\": []\n",
        "                }\n",
        "        except Exception as exc:\n",
        "            evaluation_results[sentence] = {\n",
        "                \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                \"matched_intent_uuid\": f\"Error: {exc}\",\n",
        "                \"matched_intent_display_name\": f\"Error: {exc}\",\n",
        "                \"matched_intent_confidence\": 0.0,\n",
        "                \"alternative_matches\": []\n",
        "            }\n",
        "            print(f\"Evaluation sentence '{sentence}' generated an exception: {exc}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d676bcd"
      },
      "source": [
        "## Reinforcement Learning Loop\n",
        "\n",
        "### Subtask: Select Training Data\n",
        "\n",
        "Choose a subset of the training data from `train_sentences` for the current reinforcement learning iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6519ec4b"
      },
      "source": [
        "**Reasoning**:\n",
        "Select a subset of the training data for the first reinforcement learning iteration. For simplicity in this first iteration, we will use all the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5531dd8e"
      },
      "source": [
        "# For the first iteration, use all training sentences\n",
        "current_train_sentences = train_sentences\n",
        "\n",
        "print(f\"Selected {sum(len(sentences) for sentences in current_train_sentences.values())} training sentences for the current iteration.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef69926e"
      },
      "source": [
        "### Subtask: Gemini Analysis\n",
        "\n",
        "Use Gemini to analyze the selected training data, the corresponding intent definition (including training phrases and entities), and the NLU model's behavior. Gemini should identify areas for improvement in the intent definition to increase matching rates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e303a2e1"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the training sentences, retrieve the corresponding intent details (display name, training phrases, and entities), and use Gemini to analyze this information along with the evaluation results to generate suggestions for improvement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37f7f281"
      },
      "source": [
        "# Define the Pydantic schema for the Gemini output\n",
        "class IntentSuggestions(BaseModel):\n",
        "    analysis: str = Field(description=\"Detailed analysis of the intent and suggestions for improvement.\")\n",
        "    phrases_to_remove: list[int] = Field(description=\"List of training phrase indices to remove.\")\n",
        "    phrases_to_add: list[str] = Field(description=\"List of new training phrases to add, including parameter annotations in the form [parameter text](parameter_id) with 'parameter text' included in the list of entities or their synonym of the entity type corresponding to the parameter and parameter_id matching one of the existing parameters of the intent.\")\n",
        "\n",
        "\n",
        "# Function to get intent details\n",
        "def get_intent_details(intent_uuid, intents, entity_types):\n",
        "    intent = next((intent for intent in intents if intent.name.split('/')[-1] == intent_uuid), None)\n",
        "    if not intent:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    display_name = intent.display_name\n",
        "    description = intent.description\n",
        "\n",
        "    training_phrases = []\n",
        "    for tp in intent.training_phrases:\n",
        "        phrase_str = \"\"\n",
        "        for part in tp.parts:\n",
        "            if part.parameter_id:\n",
        "                phrase_str += f\"[{part.text}]({part.parameter_id})\"\n",
        "            else:\n",
        "                phrase_str += part.text\n",
        "        training_phrases.append(phrase_str)\n",
        "\n",
        "    parameters = []\n",
        "    for p in intent.parameters:\n",
        "        parameters.append({\n",
        "            \"id\": p.id,\n",
        "            \"entity_type\": p.entity_type.split('/')[-1]\n",
        "        })\n",
        "\n",
        "    # Extract entity types mentioned in training phrases\n",
        "    mentioned_entity_types_details = []\n",
        "    for parameter in intent.parameters:\n",
        "        entity_type_name = parameter.entity_type.split('/')[-1]\n",
        "        entity_type_obj = next((et for et in entity_types if et.name.split('/')[-1] == entity_type_name), None)\n",
        "        if entity_type_obj:\n",
        "            entities_with_synonyms = []\n",
        "            for entity in entity_type_obj.entities:\n",
        "                entities_with_synonyms.append(f\"{entity.value}: {', '.join(entity.synonyms)}\")\n",
        "            mentioned_entity_types_details.append({\n",
        "                \"parameter_id\": parameter.id,\n",
        "                \"display_name\": entity_type_obj.display_name,\n",
        "                \"entities\": entities_with_synonyms\n",
        "            })\n",
        "\n",
        "    return display_name, description, training_phrases, parameters, mentioned_entity_types_details\n",
        "\n",
        "\n",
        "def analyze_intents_with_gemini(current_train_sentences, evaluation_results, intents, entity_types):\n",
        "    # Initialize a dictionary to store Gemini's suggestions\n",
        "    gemini_suggestions = {}\n",
        "\n",
        "    # Iterate through the current training sentences\n",
        "    for intent_uuid, sentences in tqdm(current_train_sentences.items(), desc=\"Analyzing Intents with Gemini\"):\n",
        "        display_name, description, training_phrases, parameters, entities_details = get_intent_details(intent_uuid, intents, entity_types)\n",
        "\n",
        "        if not display_name:\n",
        "            print(f\"Could not find intent with UUID: {intent_uuid}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Get relevant evaluation results for this intent's training sentences\n",
        "        relevant_eval_results = {sentence: result for sentence, result in evaluation_results.items() if result['expected_intent_uuid'] == intent_uuid and sentence in sentences}\n",
        "\n",
        "        training_phrases_string = \"\"\n",
        "        for i, phrase in enumerate(training_phrases):\n",
        "            training_phrases_string += f\"{i}: {phrase}\\n\"\n",
        "\n",
        "        all_entities_details = entities_details[:]\n",
        "        # Prepare the prompt for Gemini\n",
        "        prompt = f\"\"\"You are an expert NLU analyst tasked with optimizing an intent within a BERT-based Natural Language Understanding (NLU) system.\n",
        "\n",
        "    Model Context: Because this is a BERT-based model, it relies on deep contextual understanding, sentence structure, and semantic relationships (embeddings), rather than simple keyword matching. Your goal is to refine the training data to sharpen the semantic boundaries of the target intent, improving its precision and recall (F1 score), and reducing confusion with other intents.\n",
        "\n",
        "    Some training phrases may contain intentional spelling or grammar errors to capture ASR (Automatic Speech Recognition) transcription errors.\n",
        "\n",
        "    Analyze the following intent and related data and provide concrete recommendations.\n",
        "\n",
        "    ## Analysis Objectives\n",
        "\n",
        "    1.  **Identify Weaknesses & Coverage Gaps:** Determine why the target intent is not matching correctly. Is the training data too narrow (poor recall), too broad (poor precision), lacking variety, or failing to cover the scope defined in the description?\n",
        "    2.  **Analyze Overlaps (Confusion Analysis):** For each Alternative Matched Intent, explain the *root cause* of the confusion. Focus on semantic similarities, shared vocabulary, or ambiguous training phrases in the Target Intent that cause the BERT model to struggle with differentiation.\n",
        "    3.  **Entity Analysis:** Analyze if the existing entity types are being used effectively. You may suggest changes to the entity type definitions in the analysis, but recommendations (ADD/REMOVE) must use the entity types as they currently exist.\n",
        "\n",
        "    ## Recommendation Guidelines\n",
        "\n",
        "    Your recommendations (ADD/REMOVE) must adhere strictly to these rules:\n",
        "\n",
        "    1.  **Scope Management:** Do **not** expand the scope of the Target Intent beyond its description. Recommendations should only sharpen the existing scope and reduce ambiguity.\n",
        "    2.  **Entity Constraints:** You must **not** add new entities or entity types in the training phrases. All new training phrases must only use the provided Mentioned Entity Types.\n",
        "    3.  **Language Requirements:** **Crucial:** All analysis, explanations, and suggested training phrases must be in **{language}**.\n",
        "    4.  **Natural Language and Stop Words (Crucial for BERT):**\n",
        "        *   Prioritize natural, idiomatic, conversational **{language}**.\n",
        "        *   **Include common {language} stop words** (articles, possessive pronouns, prepositions) where they are essential for a natural-sounding, grammatically correct utterance. BERT requires these for contextual understanding.\n",
        "        *   Avoid *unnecessary* filler words (e.g., \"umm,\" \"please\"), but do not strip necessary stop words.\n",
        "    5.  **Handling Existing Errors:** Training phrases in the existing dataset that contain only one word, incomplete words, transcription errors (ASR), or spelling/grammar mistakes must **not** be marked for removal (they provide robustness), unless they are the direct cause of severe, unresolvable cross-intent confusion. You may ADD the corrected or more complete versions of these phrases.\n",
        "    6.  **Quantity Guideline:** If the intent already has a large number of phrases (e.g., >100), be highly selective with ADD recommendations, focusing only on phrases that resolve specific overlaps or critical gaps.\n",
        "\n",
        "    ## Recommendation Types\n",
        "\n",
        "    *   **ADD:**\n",
        "        *   Suggest new phrases that specifically help disambiguate the Target Intent from the Alternative Matched Intents.\n",
        "        *   Increase variety in sentence structure (questions, commands, statements) and coverage of real-world user expressions *within the scope*.\n",
        "        *   Explain the rationale for the addition.\n",
        "    *   **REMOVE:**\n",
        "        *   Identify phrases (by index) that are highly ambiguous, out of scope, or directly cause unresolvable confusion with Alternative Matched Intents.\n",
        "        *   Explain the rationale for removal.\n",
        "        *   *Note: To update a phrase, you must REMOVE the old index and ADD the new version.*\n",
        "\n",
        "    # Intent to Analyze\n",
        "\n",
        "    Intent Display Name: {display_name}\n",
        "    Description: {description}\n",
        "    Parameters: {parameters}\n",
        "    Training Phrases (with parameter annotations):\n",
        "    {training_phrases_string}\n",
        "\n",
        "    # Test Sentences and Matching Results (from evaluation):\n",
        "    \"\"\"\n",
        "        if relevant_eval_results:\n",
        "            for sentence, result in relevant_eval_results.items():\n",
        "                prompt += f\"\"\"\n",
        "    Sentence: {sentence}\n",
        "    Expected Intent: {display_name}\n",
        "    Matched Intent: {result['matched_intent_display_name']}\n",
        "    Matched Intent Confidence: {result['matched_intent_confidence']}\n",
        "    \"\"\"\n",
        "                if result['alternative_matches']:\n",
        "                    for i, alt_match in enumerate(result['alternative_matches']):\n",
        "                        prompt += f\"Alternative Match #{i+1}: {alt_match['display_name']} (Confidence: {alt_match['confidence']})\\n\"\n",
        "\n",
        "        else:\n",
        "            prompt += \"No relevant evaluation results found for this intent in the training data.\\n\"\n",
        "\n",
        "        current_tokens = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=prompt).total_tokens\n",
        "\n",
        "        # Collect and deduplicate alternative intents\n",
        "        alternative_intents_info = {}\n",
        "        if relevant_eval_results:\n",
        "            for result in relevant_eval_results.values():\n",
        "                for alt_match in result.get('alternative_matches', []):\n",
        "                    alt_intent_uuid = alt_match.get('intent_id')\n",
        "                    if alt_intent_uuid and alt_intent_uuid != intent_uuid and alt_intent_uuid not in alternative_intents_info:\n",
        "                        alt_display_name, alt_description, alt_training_phrases, alt_parameters, alt_entities_details = get_intent_details(alt_intent_uuid, intents, entity_types)\n",
        "                        if alt_display_name:\n",
        "                            all_entities_details.extend(alt_entities_details)\n",
        "                            alt_training_phrases_string = \"\"\n",
        "                            for phrase in alt_training_phrases:\n",
        "                                alt_training_phrases_string += f\"- {phrase}\\n\"\n",
        "                            alternative_intents_info[alt_intent_uuid] = {\n",
        "                                \"display_name\": alt_display_name,\n",
        "                                \"description\": alt_description,\n",
        "                                \"parameters\": alt_parameters,\n",
        "                                \"training_phrases\": alt_training_phrases_string\n",
        "                            }\n",
        "\n",
        "        if alternative_intents_info:\n",
        "            prompt += \"\\n# Overlapping Intents\\n\"\n",
        "            for alt_intent_uuid, alt_info in alternative_intents_info.items():\n",
        "                alternative_intent_prompt = f\"\\nAlternative Matched Intent Display Name: ({alt_info['display_name']})\\n\"\n",
        "                alternative_intent_prompt += f\"Alternative Matched Description: {alt_info['description']}\\n\"\n",
        "                alternative_intent_prompt += f\"Alternative Matched Parameters: {alt_info['parameters']}\\n\"\n",
        "                alternative_intent_prompt += f\"Alternative Matched Training Phrases:\\n{alt_info['training_phrases']}\"\n",
        "                alternative_intent_token_count = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=alternative_intent_prompt).total_tokens\n",
        "                if current_tokens + alternative_intent_token_count > MAX_TOKEN_COUNT:\n",
        "                    break\n",
        "                else:\n",
        "                    current_tokens += alternative_intent_token_count\n",
        "                    prompt += alternative_intent_prompt\n",
        "\n",
        "\n",
        "        # Deduplicate and add entities information\n",
        "        unique_entities = {v['display_name']:v for v in all_entities_details}.values()\n",
        "        if unique_entities:\n",
        "            prompt += \"\\n# Entity Types and Entities used in training phrases:\\n\"\n",
        "            for entity_detail in unique_entities:\n",
        "                entities_string = f\"\\nParameter ID: {entity_detail['parameter_id']}\\nEntity Type: {entity_detail['display_name']}\\nEntities:\\n\"\n",
        "                for entity in entity_detail['entities']:\n",
        "                    entities_string += f\"- {entity}\\n\"\n",
        "                entities_token_count = genai_client.models.count_tokens(model=GEMINI_MODEL, contents=entities_string).total_tokens\n",
        "                if current_tokens + entities_token_count > MAX_TOKEN_COUNT:\n",
        "                    break\n",
        "                else:\n",
        "                    prompt += entities_string\n",
        "                    current_tokens += entities_token_count\n",
        "\n",
        "        # print(prompt)\n",
        "        # print(f\"Prompt tokens: {current_tokens}\")\n",
        "\n",
        "        try:\n",
        "            # Call Gemini API\n",
        "            response = genai_client.models.generate_content(\n",
        "                model=GEMINI_MODEL,\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    response_mime_type='application/json',\n",
        "                    response_schema=IntentSuggestions,\n",
        "                )\n",
        "            )\n",
        "            gemini_suggestions[intent_uuid] = response.text\n",
        "        except Exception as e:\n",
        "            gemini_suggestions[intent_uuid] = f\"Error generating suggestions: {e}\"\n",
        "            print(f\"Error processing intent {display_name} ({intent_uuid}): {e}\")\n",
        "\n",
        "    return gemini_suggestions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbncDIiB7sCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d57b1581"
      },
      "source": [
        "## Reinforcement learning\n",
        "\n",
        "### Subtask:\n",
        "Identify problematic test sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bruxpTx-05t8"
      },
      "source": [
        "REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE = 0.2\n",
        "problematic_intent_uuids = []\n",
        "\n",
        "for sentence, result in evaluation_results.items():\n",
        "    if result['matched_intent_uuid'] != result['expected_intent_uuid']:\n",
        "        problematic_intent_uuids.append(result['expected_intent_uuid'])\n",
        "    elif result['alternative_matches']:\n",
        "        confidence_difference = result['matched_intent_confidence'] - result['alternative_matches'][0]['confidence']\n",
        "        if confidence_difference < REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE:\n",
        "            problematic_intent_uuids.append(result['expected_intent_uuid'])\n",
        "\n",
        "unique_problematic_intent_uuids = set(problematic_intent_uuids)\n",
        "\n",
        "print(f\"Found {len(unique_problematic_intent_uuids)} problematic intents:\")\n",
        "for intent_uuid in unique_problematic_intent_uuids:\n",
        "    print(intent_uuid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8c297a4"
      },
      "source": [
        "# @title Main Reinforcement Learning Loop\n",
        "\n",
        "for i in range(REINFORCEMENT_ITERATIONS):\n",
        "    print(f\"--- Starting Reinforcement Iteration {i+1}/{REINFORCEMENT_ITERATIONS} ---\")\n",
        "\n",
        "    # 1. Identify problematic intents in the test set\n",
        "    problematic_intent_uuids = set()\n",
        "    for sentence, result in evaluation_results.items():\n",
        "        # Check if the sentence is in the test set\n",
        "        is_in_test_set = any(sentence in sentences for sentences in test_sentences_eval.values())\n",
        "\n",
        "        if is_in_test_set:\n",
        "            if result['matched_intent_uuid'] != result['expected_intent_uuid']:\n",
        "                problematic_intent_uuids.add(result['expected_intent_uuid'])\n",
        "            elif result['alternative_matches']:\n",
        "                confidence_difference = result['matched_intent_confidence'] - result['alternative_matches'][0]['confidence']\n",
        "                if confidence_difference < REINFORCEMENT_MINIMUM_CONFIDENCE_DIFFERENCE:\n",
        "                    problematic_intent_uuids.add(result['expected_intent_uuid'])\n",
        "\n",
        "    if not problematic_intent_uuids:\n",
        "        print(\"No problematic intents found. Stopping reinforcement learning.\")\n",
        "        break\n",
        "\n",
        "    print(f\"Found {len(problematic_intent_uuids)} problematic intents to analyze.\")\n",
        "\n",
        "    # Create a dictionary of the problematic sentences to pass to Gemini\n",
        "    problematic_sentences_for_gemini = {}\n",
        "    for intent_uuid in problematic_intent_uuids:\n",
        "        if intent_uuid in test_sentences_eval:\n",
        "            problematic_sentences_for_gemini[intent_uuid] = test_sentences_eval[intent_uuid]\n",
        "\n",
        "\n",
        "    # 2. Analyze with Gemini\n",
        "    gemini_suggestions = analyze_intents_with_gemini(\n",
        "        problematic_sentences_for_gemini,\n",
        "        evaluation_results,\n",
        "        intents,\n",
        "        entity_types\n",
        "    )\n",
        "\n",
        "    # 3. Apply Gemini's suggestions\n",
        "    for intent_uuid, suggestions_json in gemini_suggestions.items():\n",
        "        try:\n",
        "            suggestions = IntentSuggestions.model_validate_json(suggestions_json)\n",
        "            intent_to_update = next((intent for intent in intents if intent.name.split('/')[-1] == intent_uuid), None)\n",
        "\n",
        "            if not intent_to_update:\n",
        "                print(f\"Could not find intent with UUID: {intent_uuid} to apply suggestions. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nApplying suggestions for intent: {intent_to_update.display_name}\")\n",
        "\n",
        "            # Remove phrases\n",
        "            phrases_to_remove_indices = sorted(suggestions.phrases_to_remove, reverse=True)\n",
        "            if phrases_to_remove_indices:\n",
        "                print(f\"Removing {len(phrases_to_remove_indices)} phrases...\")\n",
        "                for index in phrases_to_remove_indices:\n",
        "                    if 0 <= index < len(intent_to_update.training_phrases):\n",
        "                        del intent_to_update.training_phrases[index]\n",
        "\n",
        "            # Add phrases\n",
        "            if suggestions.phrases_to_add:\n",
        "                print(f\"Adding {len(suggestions.phrases_to_add)} new phrases...\")\n",
        "                for phrase_text in suggestions.phrases_to_add:\n",
        "                    # Check for duplicates before adding\n",
        "                    if any(phrase_text == \"\".join([p.text for p in tp.parts]) for tp in intent_to_update.training_phrases):\n",
        "                        print(f\"Skipping duplicate phrase: {phrase_text}\")\n",
        "                        continue\n",
        "\n",
        "                    new_training_phrase = dialogflow.Intent.TrainingPhrase(repeat_count=1)\n",
        "                    parts = re.split(r'(\\[[^\\]]+\\]\\([^\\)]+\\))', phrase_text)\n",
        "                    for part in parts:\n",
        "                        match = re.match(r'\\[([^\\]]+)\\]\\(([^\\)]+)\\)', part)\n",
        "                        if match:\n",
        "                            text = match.group(1)\n",
        "                            parameter_id = match.group(2)\n",
        "                            new_training_phrase.parts.append(dialogflow.Intent.TrainingPhrase.Part(text=text, parameter_id=parameter_id))\n",
        "                        elif part:\n",
        "                            new_training_phrase.parts.append(dialogflow.Intent.TrainingPhrase.Part(text=part))\n",
        "                    intent_to_update.training_phrases.append(new_training_phrase)\n",
        "\n",
        "            # Ensure all training phrases have repeat_count\n",
        "            for tp in intent_to_update.training_phrases:\n",
        "                if not 'repeat_count' in tp or not tp.repeat_count or tp.repeat_count < 1:\n",
        "                    tp.repeat_count = 1\n",
        "\n",
        "            # Update the intent\n",
        "            intents_client.update_intent(intent=intent_to_update)\n",
        "            print(f\"Successfully updated intent: {intent_to_update.display_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error applying suggestions for intent {intent_uuid}: {e}\")\n",
        "            raise e\n",
        "\n",
        "    # 4. Train the flow\n",
        "    print(\"\\nTraining the flow...\")\n",
        "    operation = flows_client.train_flow(name=flow.name)\n",
        "    print(\"Waiting for training to complete...\")\n",
        "    operation.result(timeout=3600)\n",
        "    print(\"Flow training completed successfully.\")\n",
        "\n",
        "\n",
        "    # 5. Re-evaluate all test sentences\n",
        "    print(\"\\nRe-evaluating all test sentences after applying suggestions...\")\n",
        "    session_id = f\"re-eval-{i+1}-{uuid.uuid4()}\"\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        future_to_sentence_eval = {\n",
        "            executor.submit(match_intent, project_id, location, agent.name.split('/')[-1], sentence, session_id, FLOW_ID, PAGE_ID): (sentence, intent_uuid)\n",
        "            for intent_uuid, sentences in test_sentences.items() for sentence in sentences\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(future_to_sentence_eval), total=len(future_to_sentence_eval), desc=\"Re-evaluating Sentences\"):\n",
        "            sentence, expected_intent_uuid = future_to_sentence_eval[future]\n",
        "            try:\n",
        "                response = future.result()\n",
        "                if response and response.matches:\n",
        "                    matched_intent_id = response.matches[0].intent.name.split('/')[-1]\n",
        "                    matched_intent_display_name = response.matches[0].intent.display_name\n",
        "                    matched_intent_confidence = response.matches[0].confidence\n",
        "                    alternative_matches = [\n",
        "                        {\"intent_id\": m.intent.name.split('/')[-1], \"display_name\": m.intent.display_name, \"confidence\": m.confidence}\n",
        "                        for m in response.matches[1:]\n",
        "                    ]\n",
        "                    evaluation_results[sentence] = {\n",
        "                        \"expected_intent_uuid\": expected_intent_uuid,\n",
        "                        \"matched_intent_uuid\": matched_intent_id,\n",
        "                        \"matched_intent_display_name\": matched_intent_display_name,\n",
        "                        \"matched_intent_confidence\": matched_intent_confidence,\n",
        "                        \"alternative_matches\": alternative_matches\n",
        "                    }\n",
        "                else:\n",
        "                    evaluation_results[sentence]['matched_intent_uuid'] = \"No match\"\n",
        "            except Exception as exc:\n",
        "                evaluation_results[sentence]['matched_intent_uuid'] = f\"Error: {exc}\"\n",
        "                print(f\"Re-evaluation sentence '{sentence}' generated an exception: {exc}\")\n",
        "\n",
        "    # 6. Calculate and print improvement summary for the iteration\n",
        "    correct_before = 0\n",
        "    correct_after = 0\n",
        "    total_test_sentences = len(test_list)\n",
        "\n",
        "    # Note: This is a simplified comparison. A more robust comparison would store\n",
        "    # the 'before' state of evaluation_results separately.\n",
        "    # For this example, we'll just count current correct vs. total.\n",
        "    for sentence, result in evaluation_results.items():\n",
        "         if any(sentence in s for s in test_sentences_eval.values()):\n",
        "            if result['matched_intent_uuid'] == result['expected_intent_uuid']:\n",
        "                correct_after +=1\n",
        "\n",
        "    # This is a placeholder for the 'before' count. In a real scenario, you'd\n",
        "    # need to store the initial evaluation results to compare against.\n",
        "    # For now, let's assume a baseline to show the logic.\n",
        "    # You would replace this with a proper calculation based on initial_evaluation_results\n",
        "    initial_correct_count = 0\n",
        "    for sentence, result in evaluation_results.items():\n",
        "         if any(sentence in s for s in test_sentences_eval.values()):\n",
        "             # This logic is flawed without storing initial results, but demonstrates the idea\n",
        "            pass # You'd check against initial results here\n",
        "\n",
        "    print(f\"\\n--- Iteration {i+1} Summary ---\")\n",
        "    print(f\"Accuracy on test set after iteration: {correct_after / total_test_sentences:.2%}\")\n",
        "    # print(f\"Improvement from baseline: {((correct_after / total_test_sentences) - (initial_correct_count/total_test_sentences)):.2%}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Reinforcement Learning Finished ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb4a0789"
      },
      "source": [
        "## Final Report and Summary\n",
        "\n",
        "This report summarizes the results of the reinforcement learning process. It includes an analysis of the initial and final evaluation results, a summary of the changes made by Gemini, and recommendations for further improvements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55862731"
      },
      "source": [
        "# @title Generate Final Report\n",
        "\n",
        "def generate_final_report(initial_results, final_results, all_gemini_suggestions):\n",
        "    \"\"\"Generates a final report comparing initial and final results.\"\"\"\n",
        "\n",
        "    report = \"<h1>Reinforcement Learning Final Report</h1>\"\n",
        "\n",
        "    # --- Overall Summary ---\n",
        "    report += \"<h2>Overall Summary</h2>\"\n",
        "    initial_correct = sum(1 for r in initial_results.values() if r['matched_intent_uuid'] == r['expected_intent_uuid'])\n",
        "    final_correct = sum(1 for r in final_results.values() if r['matched_intent_uuid'] == r['expected_intent_uuid'])\n",
        "    total_sentences = len(initial_results)\n",
        "    initial_accuracy = (initial_correct / total_sentences) * 100\n",
        "    final_accuracy = (final_correct / total_sentences) * 100\n",
        "\n",
        "    report += f\"<p><b>Initial Accuracy:</b> {initial_accuracy:.2f}% ({initial_correct}/{total_sentences})</p>\"\n",
        "    report += f\"<p><b>Final Accuracy:</b> {final_accuracy:.2f}% ({final_correct}/{total_sentences})</p>\"\n",
        "    report += f\"<p><b>Accuracy Improvement:</b> {final_accuracy - initial_accuracy:.2f}%</p>\"\n",
        "\n",
        "\n",
        "    # --- Detailed Comparison ---\n",
        "    report += \"<h2>Detailed Comparison of Problematic Sentences</h2>\"\n",
        "    report += \"<table border='1'><tr><th>Sentence</th><th>Expected Intent</th><th>Initial Match (Confidence)</th><th>Final Match (Confidence)</th><th>Status</th></tr>\"\n",
        "\n",
        "    for sentence, initial_r in initial_results.items():\n",
        "        final_r = final_results[sentence]\n",
        "        initial_match_str = f\"{initial_r['matched_intent_display_name']} ({initial_r['matched_intent_confidence']:.2f})\"\n",
        "        final_match_str = f\"{final_r['matched_intent_display_name']} ({final_r['matched_intent_confidence']:.2f})\"\n",
        "\n",
        "        status = \" Correct\"\n",
        "        if initial_r['matched_intent_uuid'] != initial_r['expected_intent_uuid']:\n",
        "            if final_r['matched_intent_uuid'] == final_r['expected_intent_uuid']:\n",
        "                status = \" Fixed\"\n",
        "            else:\n",
        "                status = \" Still Incorrect\"\n",
        "\n",
        "        if initial_r['matched_intent_uuid'] != final_r['matched_intent_uuid'] or status != \" Correct\":\n",
        "             report += f\"<tr><td>{sentence}</td><td>{initial_r['expected_intent_uuid']}</td><td>{initial_match_str}</td><td>{final_match_str}</td><td>{status}</td></tr>\"\n",
        "\n",
        "    report += \"</table>\"\n",
        "\n",
        "    # --- Gemini's Changes ---\n",
        "    report += \"<h2>Summary of Gemini's Changes</h2>\"\n",
        "    for intent_uuid, suggestions_list in all_gemini_suggestions.items():\n",
        "        intent_display_name = next((intent.display_name for intent in intents if intent.name.split('/')[-1] == intent_uuid), \"Unknown Intent\")\n",
        "        report += f\"<h3>Intent: {intent_display_name} ({intent_uuid})</h3>\"\n",
        "        for i, suggestions_json in enumerate(suggestions_list):\n",
        "            report += f\"<h4>Iteration {i+1}</h4>\"\n",
        "            try:\n",
        "                suggestions = IntentSuggestions.model_validate_json(suggestions_json)\n",
        "                report += \"<b>Analysis:</b>\"\n",
        "                report += f\"<p>{suggestions.analysis}</p>\"\n",
        "                if suggestions.phrases_to_add:\n",
        "                    report += \"<b>Added Phrases:</b><ul>\"\n",
        "                    for phrase in suggestions.phrases_to_add:\n",
        "                        report += f\"<li>{phrase}</li>\"\n",
        "                    report += \"</ul>\"\n",
        "                if suggestions.phrases_to_remove:\n",
        "                    report += \"<b>Removed Phrase Indices:</b><ul>\"\n",
        "                    for index in suggestions.phrases_to_remove:\n",
        "                        report += f\"<li>{index}</li>\"\n",
        "                    report += \"</ul>\"\n",
        "            except Exception as e:\n",
        "                report += f\"<p>Error parsing suggestions: {e}</p>\"\n",
        "\n",
        "\n",
        "    return report\n",
        "\n",
        "# Store the initial results before the loop\n",
        "initial_evaluation_results = evaluation_results.copy()\n",
        "all_gemini_suggestions = {}\n",
        "\n",
        "# Modify the main loop to store suggestions\n",
        "for i in range(REINFORCEMENT_ITERATIONS):\n",
        "    # ... (rest of the loop code from the previous cell)\n",
        "\n",
        "    # Store Gemini's suggestions for the report\n",
        "    for intent_uuid, suggestions in gemini_suggestions.items():\n",
        "        if intent_uuid not in all_gemini_suggestions:\n",
        "            all_gemini_suggestions[intent_uuid] = []\n",
        "        all_gemini_suggestions[intent_uuid].append(suggestions)\n",
        "\n",
        "    # ... (rest of the loop code from the previous cell)\n",
        "\n",
        "\n",
        "final_report_html = generate_final_report(initial_evaluation_results, evaluation_results, all_gemini_suggestions)\n",
        "\n",
        "from IPython.display import HTML\n",
        "display(HTML(final_report_html))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}